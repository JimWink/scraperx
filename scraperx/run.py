import os
import sys
import json
import logging
import argparse
from .utils import import_scraper
from .write_to import WriteTo

logger = logging.getLogger(__name__)


def validate_config(args):
    """Validate the scraper config file

    Arguments:
        args {argparse.Namespace} -- Cli args
    """
    logger.info(f"Validate the config file {args.config}")
    from .config import Config
    try:
        Config.get_config_from_file(args.config)
    except ValueError as e:
        logger.critical(e)
        # Should not continue if there is an issue with the config
        sys.exit(1)
    logger.info("Config file is valid")


def run_dispatch(args):
    """Kick off the dispatcher for the scraper

    Arguments:
        args {argparse.Namespace} -- Cli args
    """
    if args.dump_tasks:
        dispatcher = args.scraper.Dispatch(cli_args=args)
        # Dump data to local json file
        task_file = WriteTo(dispatcher.tasks).write_json()\
                                             .save_local('tasks.json')
        num_tasks = len(dispatcher.tasks)
        logger.info(f"Saved {num_tasks} tasks to {task_file['path']}")

    else:
        tasks = None
        if args.task_file:
            with open(args.task_file) as f:
                tasks = json.load(f)

        dispatcher = args.scraper.Dispatch(tasks=tasks, cli_args=args)
        dispatcher.dispatch(standalone=args.standalone)


def run_downloader(args):
    """Kick off the downloader for the scraper

    Arguments:
        args {argparse.Namespace} -- Cli args
    """
    for task in args.tasks:
        downloader = args.scraper.Download(task, cli_args=args)
        downloader.run(standalone=args.standalone)


def run_extractor(args):
    """Kick off the extractor for the scraper

    Arguments:
        args {argparse.Namespace} -- Cli args
    """
    if os.path.isdir(args.source):
        # source_dir = os.fsencode(args.source)
        # for file in os.listdir(source_dir):

        # extractor = args.scraper.Extract(task, cli_args=args)
        # extractor.run()
        pass
    else:
        metadata_file = f"{args.source}.metadata.json"
        metadata = {}
        with open(metadata_file) as f:
            metadata = json.load(f)

        extractor = args.scraper.Extract(metadata['task'],
                                         metadata['download_manifest'],
                                         cli_args=args)
        extractor.run()


def read_tasks(task_file):
    """Read in the tasks to a list

    Read in the json tasks file generated by the dispatcher
    and create a lists of tasks to be processed

    Arguments:
        task_file {str} -- Path the the task.json file

    Returns:
        list -- List of tasks to be processed
    """
    tasks = []
    with open(task_file) as f:
        tasks = json.load(f)

    if not isinstance(tasks, (list, tuple)):
        tasks = [tasks]

    return tasks


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Run platform3')

    subparsers = parser.add_subparsers(dest='command', help='sub-command help')

    ###
    # Validation
    ###
    parser_validate = subparsers.add_parser('validate',
                                            help="Validate the configs")
    parser_validate.add_argument('config',
                                 help="The config.yaml to validate")

    ###
    # Dispatching
    ###
    parser_dispatch = subparsers.add_parser('dispatch',
                                            help="Run the dispatcher")
    parser_dispatch.add_argument('scraper', type=import_scraper,
                                 help="The scraper module to run")

    # At least one of these in a single group must be used
    parser_dispatch.add_argument('--limit', type=int,
                                 help="Limit the number of tasks")
    # TODO: if dump-tasks, then the others below cannot be used
    parser_dispatch.add_argument('--dump-tasks', action='store_true',
                                 help=("Save the tasks as json."
                                       "Will not dispatch when set"))
    # Can be used with task-file, but only local or standalone should be set
    parser_dispatch.add_argument('--standalone', action='store_true',
                                 help="Do not trigger the downloader")
    parser_dispatch.add_argument('--local', action='store_true',
                                 help="Run/save everything locally")

    parser_dispatch.add_argument('--task-file',
                                 help="Output file from --dump-tasks")

    ratelimit_group = parser_dispatch.add_mutually_exclusive_group()
    ratelimit_group.add_argument('--qps',
                                 help='Number of tasks to dispatch a second')
    ratelimit_group.add_argument('--period', type=float,
                                 help='Dispatch all tasks in n hours')

    ###
    # Downloading
    ###
    parser_download = subparsers.add_parser('download',
                                            help="Run the downloader")
    parser_download.add_argument('scraper', type=import_scraper,
                                 help="The scraper module to run")
    parser_download.add_argument('tasks', type=read_tasks,
                                 help="Task file of things to run")
    parser_download.add_argument('--local', action='store_true',
                                 help="Save the sources locally")
    parser_download.add_argument('--standalone', action='store_true',
                                 help="Do not trigger the extractor")

    ###
    # Extracting
    ###
    parser_extract = subparsers.add_parser('extract',
                                           help="Run the extractor")
    parser_extract.add_argument('scraper', type=import_scraper,
                                help="The scraper module to run")
    parser_extract.add_argument('source',
                                help="Local dir or source file to extract")
    parser_extract.add_argument('--local', action='store_true',
                                help="Save the extracted data locally")

    args = parser.parse_args()

    command_actions = {'validate': validate_config,
                       'dispatch': run_dispatch,
                       'download': run_downloader,
                       'extract': run_extractor,
                       }
    command_actions[args.command](args)
